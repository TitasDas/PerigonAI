{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRKAmjZZP0rKeJ11dUOlqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TitasDas/PerigonAI_Interview/blob/main/Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1: Python programming, data processing.**\n",
        "\n",
        "\n",
        "\n",
        "In this problem we want to generate pseudo-random data that has certain desired statistical properties. This can be useful for demo, research or testing purposes.\n",
        "\n",
        "First, let’s generate these “desired statistical properties”.\n",
        "\n",
        "•              Generate a random 6x6 correlation matrix rho.\n",
        "\n",
        "•              Regularization: write a test checking that rho is a valid correlation matrix, and if not - find the nearest valid one.\n",
        "\n",
        "Now, let’s generate the data that would have these properties.\n",
        "\n",
        "•              Generate a set of 6 random variables (put them in a matrix 1000x6, the distribution doesn’t matter, but should be continuous), distributed between 0 and 1 with correlation defined by rho.\n",
        "\n",
        "\n",
        "\n",
        "Slightly different, but related problem.\n",
        "\n",
        "•              Apply PCA to reduce the dimensionality to 5.\n",
        "\n",
        "•              Let the output variable y = round(x6).\n",
        "\n",
        "•              Build a couple of classifiers of your choice to predict y from {x1, x2, …, x5}.\n",
        "\n",
        "•              Compare their performance."
      ],
      "metadata": {
        "id": "ZJOGefgbTjiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we generate a random correlation matrix rho as per the size definitions and make sure it is a valid correlation matrix given some assumptions."
      ],
      "metadata": {
        "id": "RbJILXtQXZxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCKdoNrkSeYx",
        "outputId": "7ff5978a-2f75-4640-bf9c-2716e771eec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.         -0.73877154 -0.047035    0.18865237 -0.1541974  -0.36650824]\n",
            " [-0.73877154  1.         -0.52315461 -1.0516195  -0.03403461  1.07231673]\n",
            " [-0.047035   -0.52315461  1.          0.7230642  -0.57358697  0.30873532]\n",
            " [ 0.18865237 -1.0516195   0.7230642   1.          0.83295554 -0.77829933]\n",
            " [-0.1541974  -0.03403461 -0.57358697  0.83295554  1.         -0.49384768]\n",
            " [-0.36650824  1.07231673  0.30873532 -0.77829933 -0.49384768  1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Generating a random 6*6 correlation matrix 'rho'\n",
        "\n",
        "import numpy as np\n",
        "A = np.random.randn(6, 6)\n",
        "\n",
        "# Symmetrize the randomly generated matrix\n",
        "A_symm = (A + A.T) / 2\n",
        "\n",
        "# Ensure the diagonal is 1\n",
        "for i in range(6):\n",
        "    A_symm[i, i] = 1\n",
        "\n",
        "# Adjust the matrix to make it a valid correlation matrix\n",
        "eigvals, eigvecs = np.linalg.eigh(A_symm)\n",
        "D = np.diag(np.maximum(eigvals, 0))\n",
        "rho = eigvecs.dot(D).dot(eigvecs.T)\n",
        "\n",
        "# Ensure the diagonal is 1 again\n",
        "for i in range(6):\n",
        "    rho[i, i] = 1\n",
        "\n",
        "print(rho)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While generating these kind of matrices we may encounter cases wherein the matrix generated is not \"positive semi-definite\". In the above procedure we have tried to fix that by zeroing out any neg eigenvalues but this doesnt always generate a matrix with correlations between -1 and 1. We can either repeat the above process or use a **\"nearcorr\"** algo to produce valid correlation matrices.\n",
        "\n",
        "Nearcorr algorithm -\n",
        "1. Start with initial matrix Y.\n",
        "2. Project Y onto space of matrices with ones on the diagonal to get R.\n",
        "3. Project R onto space of positive semidefinite matrices to get Y'.\n",
        "4. If Y' is sufficiently close to Y, then stop; otherwise, set Y = Y' and repeat.\n",
        "\n",
        "For the positive semidefinite projection, use the spectral decomposition and set any negative eigen values to zero."
      ],
      "metadata": {
        "id": "7Tn_74vAUoUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def nearcorr(A, tol=1e-5, max_iter=100):\n",
        "    n, m = A.shape\n",
        "    if n != m:\n",
        "        raise ValueError(\"Input matrix must be square.\")\n",
        "\n",
        "    # Initialize\n",
        "    Y = A.copy()\n",
        "    I = np.eye(n)\n",
        "    iteration = 0\n",
        "    convergence = False\n",
        "\n",
        "    while not convergence and iteration < max_iter:\n",
        "        iteration += 1\n",
        "\n",
        "        # Project onto the set of matrices with ones on the diagonal\n",
        "        R = Y - np.diag(np.diagonal(Y)) + I\n",
        "\n",
        "        # Project onto the set of positive semidefinite matrices\n",
        "        eigvals, eigvecs = np.linalg.eigh(R)\n",
        "        Q = np.dot(eigvecs, np.diag(np.maximum(eigvals, 0)))\n",
        "        Y_next = np.dot(Q, eigvecs.T)\n",
        "\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(Y - Y_next, 'fro') < tol:\n",
        "            convergence = True\n",
        "\n",
        "        Y = Y_next.copy()\n",
        "\n",
        "    return Y\n",
        "\n",
        "# Create a random symmetric matrix\n",
        "A = np.random.randn(6, 6)\n",
        "A_symm = (A + A.T) / 2\n",
        "\n",
        "# Adjust its diagonal to have ones\n",
        "np.fill_diagonal(A_symm, 1)\n",
        "\n",
        "# Apply the nearcorr algorithm\n",
        "correlation_matrix = nearcorr(A_symm)\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gfZ7xGhT4b-",
        "outputId": "326c0c55-a27c-4d3c-bf69-880b75bbe4f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.0000007  -0.20376603 -0.65573185  0.59972383 -0.44980238 -0.35581176]\n",
            " [-0.20376603  1.00000156  0.4015529   0.52692701  0.05677801  0.53370809]\n",
            " [-0.65573185  0.4015529   1.00000117 -0.17946673  0.72123857 -0.07198055]\n",
            " [ 0.59972383  0.52692701 -0.17946673  1.00000159 -0.55108977 -0.16123572]\n",
            " [-0.44980238  0.05677801  0.72123857 -0.55108977  1.00000052  0.09494295]\n",
            " [-0.35581176  0.53370809 -0.07198055 -0.16123572  0.09494295  1.00000072]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we check if rho is a valid correlation matrix using the following conditions -\n",
        "\n",
        "1. Its a square.\n",
        "2. Its diagonal consists of one\n",
        "3. Its symmetric\n",
        "4. Its positive semidefinite\n",
        "\n",
        "In the code below, you can test any matrix rho by passing it to adjust_to_correlation_matrix(). If rho is already a valid correlation matrix, the function will return it unchanged. If not, it will adjust rho to make it a valid correlation matrix using the nearcorr method."
      ],
      "metadata": {
        "id": "vPK1wql_WEex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def is_valid_correlation_matrix(rho):\n",
        "    # Check if square\n",
        "    if rho.shape[0] != rho.shape[1]:\n",
        "        return False\n",
        "\n",
        "    # Check if diagonal is made of ones\n",
        "    if not np.allclose(np.diag(rho), 1):\n",
        "        return False\n",
        "\n",
        "    # Check if symmetric\n",
        "    if not np.allclose(rho, rho.T):\n",
        "        return False\n",
        "\n",
        "    # Check if positive semidefinite\n",
        "    eigvals = np.linalg.eigvalsh(rho)\n",
        "    if np.any(eigvals < 0):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def adjust_to_correlation_matrix(rho):\n",
        "    if is_valid_correlation_matrix(rho):\n",
        "        return rho\n",
        "    else:\n",
        "        return nearcorr(rho)\n",
        "\n",
        "# Create a random symmetric matrix (just for testing purposes)\n",
        "A = np.random.randn(6, 6)\n",
        "A_symm = (A + A.T) / 2\n",
        "\n",
        "# Adjust its diagonal to have ones\n",
        "np.fill_diagonal(A_symm, 1)\n",
        "\n",
        "# Adjust the matrix to be a valid correlation matrix\n",
        "rho = adjust_to_correlation_matrix(A_symm)\n",
        "print(rho)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnYLrLVeWCXk",
        "outputId": "2e136135-3ec6-42f2-b54d-d87c68652c69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.00000394 -0.66080499 -0.12604101  0.94145927 -0.28860038 -0.17627801]\n",
            " [-0.66080499  1.00000235  0.14030468 -0.68219438 -0.34365582 -0.42587107]\n",
            " [-0.12604101  0.14030468  1.00000011 -0.3389069   0.14204464 -0.21709031]\n",
            " [ 0.94145927 -0.68219438 -0.3389069   1.00000489 -0.40190187  0.08996778]\n",
            " [-0.28860038 -0.34365582  0.14204464 -0.40190187  1.00000098  0.1375898 ]\n",
            " [-0.17627801 -0.42587107 -0.21709031  0.08996778  0.1375898   1.00000059]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we generate the data that would have these properties :\n",
        "\n",
        "• Generate a set of 6 random variables (put them in a matrix 1000x6, the distribution doesn’t matter, but should be continuous), distributed between 0 and 1 with correlation defined by rho.\n",
        "\n",
        "To generate this we use the Cholesky decomposition of the desired correlation matrix -\n",
        "1. Start with some uncorrelated random data.\n",
        "2. Use the Cholesky decomposition of the desired correlation matrix to transform the data so that it has the desired correlations"
      ],
      "metadata": {
        "id": "Vs4UxRlLW8mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to generate a nearest valid correlation matrix\n",
        "def nearcorr(A, tol=1e-5, max_iter=100):\n",
        "    n, m = A.shape\n",
        "    if n != m:\n",
        "        raise ValueError(\"Input matrix must be square.\")\n",
        "\n",
        "    Y = A.copy()\n",
        "    I = np.eye(n)\n",
        "    iteration = 0\n",
        "    convergence = False\n",
        "\n",
        "    while not convergence and iteration < max_iter:\n",
        "        iteration += 1\n",
        "        R = Y - np.diag(np.diagonal(Y)) + I\n",
        "        eigvals, eigvecs = np.linalg.eigh(R)\n",
        "        Q = np.dot(eigvecs, np.diag(np.maximum(eigvals, 0)))\n",
        "        Y_next = np.dot(Q, eigvecs.T)\n",
        "\n",
        "        if np.linalg.norm(Y - Y_next, 'fro') < tol:\n",
        "            convergence = True\n",
        "\n",
        "        Y = Y_next.copy()\n",
        "\n",
        "    return Y\n",
        "\n",
        "# Function to check if given matrix is a valid correlation matrix\n",
        "def is_valid_correlation_matrix(rho):\n",
        "    if rho.shape[0] != rho.shape[1]:\n",
        "        return False\n",
        "    if not np.allclose(np.diag(rho), 1):\n",
        "        return False\n",
        "    if not np.allclose(rho, rho.T):\n",
        "        return False\n",
        "    eigvals = np.linalg.eigvalsh(rho)\n",
        "    if np.any(eigvals < 0):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# Function to adjust given matrix to a valid correlation matrix\n",
        "def adjust_to_correlation_matrix(rho):\n",
        "    if is_valid_correlation_matrix(rho):\n",
        "        return rho\n",
        "    else:\n",
        "        return nearcorr(rho)\n",
        "\n",
        "# Function to generate data with given correlation matrix\n",
        "def generate_data_with_correlation(num_samples, rho):\n",
        "    chol = np.linalg.cholesky(rho)\n",
        "    z = np.random.rand(num_samples, 6)\n",
        "    x = z @ chol.T\n",
        "    x_standard = (x - x.mean(axis=0)) / x.std(axis=0)\n",
        "    x_rescaled = (x_standard - x_standard.min(axis=0)) / (x_standard.max(axis=0) - x_standard.min(axis=0))\n",
        "    return x_rescaled\n",
        "\n",
        "# Create a random symmetric matrix\n",
        "A = np.random.randn(6, 6)\n",
        "A_symm = (A + A.T) / 2\n",
        "np.fill_diagonal(A_symm, 1)\n",
        "rho = adjust_to_correlation_matrix(A_symm)\n",
        "\n",
        "# Generate the data with the desired correlation matrix\n",
        "data = generate_data_with_correlation(1000, rho)\n",
        "print(data[:5, :])  # Print first 5 rows to inspect\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "vvCSQLMiVv89",
        "outputId": "019d76ff-613b-44a0-a863-3a9aadd3c851"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ac6290746745>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Generate the data with the desired correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data_with_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print first 5 rows to inspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ac6290746745>\u001b[0m in \u001b[0;36mgenerate_data_with_correlation\u001b[0;34m(num_samples, rho)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Function to generate data with given correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_data_with_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mchol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_nonposdef\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matrix is not positive definite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_eigenvalues_nonconvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Matrix is not positive definite"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our correlation matrix adjustment method ensures the matrix is positive semidefinite, but this isn't enough to guarantee it's positive definite. A positive semidefinite matrix may still have zero eigenvalues, causing the Cholesky decomposition to fail.\n",
        "\n",
        "There are several ways to address this:\n",
        "\n",
        "1. Perturb the matrix slightly by adding a small value to the diagonal, ensuring it becomes positive definite.\n",
        "\n",
        "2. Use another decomposition method which doesn't require the matrix to be positive definite.\n",
        "\n",
        "here we try the first method and retry generating the data using the slightly modified 'generate_data_with_correlation' function that perturbs the correlation matrix if needed. This should now be resilient to the error we encountered earlier. It will adjust the correlation matrix, if needed, to ensure it's positive definite before trying to decompose it."
      ],
      "metadata": {
        "id": "hozev-BRYK0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to generate a nearest valid correlation matrix\n",
        "def nearcorr(A, tol=1e-5, max_iter=100):\n",
        "    n, m = A.shape\n",
        "    if n != m:\n",
        "        raise ValueError(\"Input matrix must be square.\")\n",
        "\n",
        "    Y = A.copy()\n",
        "    I = np.eye(n)\n",
        "    iteration = 0\n",
        "    convergence = False\n",
        "\n",
        "    while not convergence and iteration < max_iter:\n",
        "        iteration += 1\n",
        "        R = Y - np.diag(np.diagonal(Y)) + I\n",
        "        eigvals, eigvecs = np.linalg.eigh(R)\n",
        "        Q = np.dot(eigvecs, np.diag(np.maximum(eigvals, 0)))\n",
        "        Y_next = np.dot(Q, eigvecs.T)\n",
        "\n",
        "        if np.linalg.norm(Y - Y_next, 'fro') < tol:\n",
        "            convergence = True\n",
        "\n",
        "        Y = Y_next.copy()\n",
        "\n",
        "    return Y\n",
        "\n",
        "def is_valid_correlation_matrix(rho):\n",
        "    if rho.shape[0] != rho.shape[1]:\n",
        "        return False\n",
        "    if not np.allclose(np.diag(rho), 1):\n",
        "        return False\n",
        "    if not np.allclose(rho, rho.T):\n",
        "        return False\n",
        "    eigvals = np.linalg.eigvalsh(rho)\n",
        "    if np.any(eigvals < 0):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def adjust_to_correlation_matrix(rho):\n",
        "    if is_valid_correlation_matrix(rho):\n",
        "        return rho\n",
        "    else:\n",
        "        return nearcorr(rho)\n",
        "\n",
        "def generate_data_with_correlation(num_samples, rho):\n",
        "    min_eigval = np.min(np.real(np.linalg.eigvals(rho)))\n",
        "    if min_eigval <= 0:\n",
        "        rho -= 10*min_eigval * np.eye(rho.shape[0])\n",
        "\n",
        "    chol = np.linalg.cholesky(rho)\n",
        "    z = np.random.rand(num_samples, 6)\n",
        "    x = z @ chol.T\n",
        "    x_standard = (x - x.mean(axis=0)) / x.std(axis=0)\n",
        "    x_rescaled = (x_standard - x_standard.min(axis=0)) / (x_standard.max(axis=0) - x_standard.min(axis=0))\n",
        "\n",
        "    return x_rescaled\n",
        "\n",
        "# Create a random symmetric matrix\n",
        "A = np.random.randn(6, 6)\n",
        "A_symm = (A + A.T) / 2\n",
        "np.fill_diagonal(A_symm, 1)\n",
        "rho = adjust_to_correlation_matrix(A_symm)\n",
        "\n",
        "# Generate the data with the desired correlation matrix\n",
        "data = generate_data_with_correlation(1000, rho)\n",
        "print(data[:5, :])  # Print first 5 rows to inspect\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z7140QOXyGt",
        "outputId": "663c9b9c-ac67-426e-843a-cad4de752cf1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.22631914 0.67932848 0.34280903 0.62388448 0.65866416 0.592494  ]\n",
            " [0.65988948 0.46903114 0.68832468 0.42901403 0.43466355 0.53611544]\n",
            " [0.69183439 0.29144469 0.27235356 0.5191502  0.24665957 0.19213508]\n",
            " [0.50672786 0.13011309 0.27376519 0.35911791 0.40187082 0.17499456]\n",
            " [0.13599032 0.11894406 0.37158198 0.20455189 0.74808051 0.35500651]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we apply PCA to reduce the dimensionality from 6 to 5."
      ],
      "metadata": {
        "id": "Fu1Vg56_iGwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA and reduce the dimensionality to 5\n",
        "pca = PCA(n_components=5)\n",
        "data_pca = pca.fit_transform(data)\n",
        "\n",
        "print(data_pca[:5, :])  # Print the first 5 rows to inspect\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuQnuqFBYci8",
        "outputId": "039f8114-ce45-4cde-af27-419e30b84714"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.29260255e-01  2.38718088e-01  2.52424458e-01  3.36512685e-09\n",
            "   4.85350625e-09]\n",
            " [-1.49254980e-01  2.45664399e-03 -2.41362277e-01 -1.03342644e-08\n",
            "  -2.29525666e-11]\n",
            " [-1.87776055e-01 -4.83368627e-01  1.19015083e-01 -1.48916521e-08\n",
            "  -4.22719375e-09]\n",
            " [ 1.19737469e-01 -5.53056120e-01  1.47651341e-02  3.67999227e-09\n",
            "  -2.85177999e-08]\n",
            " [ 6.08969834e-01 -2.94114755e-01 -1.15220864e-01 -2.80014018e-10\n",
            "   1.60570824e-08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we round the 6th column of data."
      ],
      "metadata": {
        "id": "H5BgpRAqiWrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.round(data[:, 5])\n",
        "\n",
        "# Print the first 10 values to inspect\n",
        "print(y[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0atuu1HiOaL",
        "outputId": "d9cfe365-f899-4443-b9fa-792956ae8565"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 0. 0. 0. 1. 0. 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two classifiers we build are a Random Forest classifier and a Logistic regression classifier. We compare their performance using accuracy as the metric.\n",
        "\n",
        "Here are the steps -\n",
        "1. Split the data into training and testing sets.\n",
        "2. Train both classifiers on the training set.\n",
        "3. Predict on the test set.\n",
        "4. Compare their accuracy."
      ],
      "metadata": {
        "id": "e9Gszw_siofP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Train classifiers\n",
        "rf.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained classifiers\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_lr:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54hRF2Adid9-",
        "outputId": "c6985ef1-7e17-4abd-83c9-53edcaae83b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.98\n",
            "Logistic Regression Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2vnEWaLtjEwC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}